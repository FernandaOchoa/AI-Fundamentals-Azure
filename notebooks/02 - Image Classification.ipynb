{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Clasificación de imágenes\r\n",
        "\r\n",
        "*Computer Vision*, de Cognitive Services, incluye modelos prediseñados útiles para trabajar con imágenes. Sin embargo, normalmente tendrá que entrenar su propio modelo para adaptarlo a Computer Vision. Por ejemplo, supongamos que Northwind Traders quiere crear un sistema de pago automatizado que identifique los artículos que los clientes quieren comprar basándose en una imagen obtenida mediante una cámara en la zona de pago. Para hacerlo, necesitará un modelo de clasificación entrenado que pueda clasificar las imágenes para, así, identificar el artículo que se quiere comprar.\r\n",
        "\r\n",
        "![Un robot sujetando unas hojas, clasificando imágenes de una manzana, banana y una naranja](./images/image-classification.jpg)\r\n",
        "\r\n",
        "En Azure, puede usar ***Custom Vision***, que forma parte de Cognitive Services, para entrenar un modelo de clasificación de imágenes basado en imágenes existentes. Hay dos elementos esenciales para crear una solución de clasificación de imágenes. Primero, debe entrenar un modelo que reconozca diferentes clases con imágenes existentes. Después, cuando el modelo esté entrenado, debe publicarlo como un servicio que las aplicaciones puedan consumir.\r\n",
        "\r\n",
        "## Crear un recurso de Custom Vision\r\n",
        "\r\n",
        "Para usar el servicio Custom Vision, necesita un recurso de Azure que pueda usar para *entrenar* un modelo, y un recurso con el que *publicarlo* para que las aplicaciones lo usen. El recurso de cada una (o ambas) de las tareas pueden ser un recurso general de **Cognitive Services** o un recurso específico de **Custom Vision**. Puede usar el mismo recurso de Cognitive Services para cada una de esas tareas, o puede usar diferentes recursos (en la misma región) de cada tarea para administrar los costes de forma independiente.\r\n",
        "\r\n",
        "Use las siguientes instrucciones para crear un nuevo recurso de **Custom Vision**.\r\n",
        "\r\n",
        "1. En una nueva pestaña del navegador, abra Azure Portal ([https://portal.azure.com](https://portal.azure.com)) e inicie sesión con la cuenta de Microsoft asociada a su suscripción de Azure.\r\n",
        "2. Haga clic en el botón **&#65291;Crear un recurso**, busque *Custom Vision* y cree un recurso de **Custom Vision** con esta configuración:\r\n",
        "    - **Opciones de creación**: ambas\r\n",
        "    - **Suscripción**: *su suscripción de Azure*\r\n",
        "    - **Grupo de recursos**: *seleccione o cree un grupo de recursos con un nombre único*\r\n",
        "    - **Nombre**: *escriba un nombre único*\r\n",
        "    - **Ubicación de entrenamiento**: *seleccione cualquier región disponible*\r\n",
        "    - **Plan de tarifa de entrenamiento**: F0\r\n",
        "    - **Ubicación de la predicción**: *la misma región del recurso de entrenamiento*\r\n",
        "    - **Plan de tarifa de predicción**: F0\r\n",
        "\r\n",
        "    > **Nota**: Si ya tiene un servicio Custom Vision F0 en su suscripción, seleccione **S0** en este caso.\r\n",
        "\r\n",
        "3. Espere a que se creen los recursos, verá que se aprovisionan dos recursos de Custom Vision, uno para el entrenamiento y otro para la predicción. Para ver estos recursos, vaya al grupo de recursos en el que los creó.\r\n",
        "\r\n",
        "## Crear un proyecto de Custom Vision\r\n",
        "\r\n",
        "Para entrenar un modelo de detección de objetos, debe crear un proyecto de Custom Vision basado en su recurso de entrenamiento. Para hacerlo, debe usar el portal de Custom Vision.\r\n",
        "\r\n",
        "1. Descargue y extraiga las imágenes de entrenamiento de https://aka.ms/fruit-images.\r\n",
        "2. En la pestaña de otro explorador, abra el portal de Custom Vision ([https://customvision.ai](https://customvision.ai)). Si se le solicita, inicie sesión con la cuenta de Microsoft asociada a su suscripción de Azure y acepte las Condiciones del servicio\r\n",
        "3. En el portal de Custom Vision, cree un nuevo proyecto con la siguiente configuración:\r\n",
        "    - **Name**: Grocery Checkout\r\n",
        "    - **Description**: Image classification for groceries\r\n",
        "    - **Resource**: *The Custom Vision resource you created previously*\r\n",
        "    - **Project Types**: Classification\r\n",
        "    - **Classification Types**: Multiclass (single tag per image)\r\n",
        "    - **Domains**: Food\r\n",
        "4. Haga clic en **\\[+\\] Add images** y seleccione todos los archivos de la carpeta **apple** extraídos anteriormente. Después, cargue los archivos de imágenes e incluya la etiqueta *apple*, como en este ejemplo:\r\n",
        "\r\n",
        "![Cargar la manzana con la etiqueta apple](./images/upload_apples.jpg)\r\n",
        "   \r\n",
        "5. Repita el paso anterior para cargar las imágenes de la carpeta **banana** con la etiqueta *banana* y las imágenes de la carpeta **orange** con la etiqueta *orange*.\r\n",
        "6. Explore las imágenes cargadas en el proyecto de Custom Vision, debería tener 15 imágenes de cada clase, como en este ejemplo:\r\n",
        "\r\n",
        "![Imágenes de frutas etiquetadas: 15 manzanas, 15 bananas y 15 naranjas](./images/fruit.jpg)\r\n",
        "    \r\n",
        "7. En el proyecto de Custom Vision, sobre las imágenes, haga clic en **Train** para entrenar un modelo de clasificación con las imágenes etiquetadas. Seleccione la opción **Quick Training** y, después, espere a que se complete el entrenamiento (puede tardar alrededor de un minuto).\r\n",
        "8. Una vez entrenado el modelo, compruebe las métricas de rendimiento *Precision*, *Recall* y *AP* (miden la precisión de la predicción del modelo de clasificación y sus valores deberían ser altos).\r\n",
        "\r\n",
        "## Prueba del modelo\r\n",
        "\r\n",
        "Debe probar la iteración del modelo antes de publicarla para que las aplicaciones la usen.\r\n",
        "\r\n",
        "1. Sobre las métricas de rendimiento, haga clic en **Quick Test**.\r\n",
        "2. En el cuadro **Image URL**, escriba `https://aka.ms/apple-image` y haga clic en &#10132;.\r\n",
        "3. Consulte las predicciones obtenidas del modelo, la puntuación de probabilidad de *apple* debería ser la más alta, como en este ejemplo:\r\n",
        "\r\n",
        "![Una imagen con una predicción de clase de una manzana](./images/test-apple.jpg)\r\n",
        "\r\n",
        "4. Cierre la ventana **Quick Test**.\r\n",
        "\r\n",
        "## Publicar y consumir el modelo de clasificación de imágenes\r\n",
        "\r\n",
        "Ya puede publicar su modelo entrenado y usarlo desde una aplicación de cliente.\r\n",
        "\r\n",
        "9. Haga clic en **&#128504; Publish** para publicar el modelo entrenado con la siguiente configuración:\r\n",
        "    - **Model name**: groceries\r\n",
        "    - **Prediction Resource**: *el recurso de predicción creado anteriormente*\r\n",
        "\r\n",
        "### (!) Comprobar \r\n",
        "¿Ha usado el mismo nombre de modelo: **groceries**?   \r\n",
        "\r\n",
        "10. Después de publicarlo, haga clic en el icono *Settings* (&#9881;) en la esquina superior derecha de la página **Performance** para ver la configuración del proyecto. Después, en **General** (a la izquierda), copie el **Project Id**. Vaya hacia abajo y péguelo en la celda de código debajo del paso 13, en sustitución de **YOUR_PROJECT_ID**.\r\n",
        "\r\n",
        "![ID de proyecto en la configuración del proyecto](./images/cv_project_settings.jpg)\r\n",
        "\r\n",
        "> _**Nota**: Si usó un recurso de **Cognitive Services** en lugar de crear un recurso de **Custom Vision** al principio del ejercicio, puede copiar su clave y punto de conexión desde el lado derecho de la configuración del proyecto, péguelos en la celda de código que aparece más abajo y ejecútela para ver los resultados. Si no es así, siga los pasos que quedan para obtener la clave y el punto de conexión de su recurso de predicción de Custom Vision._\r\n",
        "\r\n",
        "11. En la parte superior izquierda de la página **Project Settings**, haga clic en el icono *Projects Gallery* (&#128065;) para volver a la página principal del portal de Custom Vision, donde debería aparecer su proyecto.\r\n",
        "\r\n",
        "12. En la página principal del portal de Custom Vision, en la esquina superior derecha, haga clic en el icono *Settings* (&#9881;) para ver la configuración de su servicio Custom Vision. Después, en **Resources**, abra su recurso de **predicción** (<u>no</u> el recurso de entrenamiento) y copie sus valores para **Key** y **Endpoint** en la celda de código que aparece debajo del paso 13, en sustitución de **YOUR_KEY** y **YOUR_ENDPOINT**.\r\n",
        "\r\n",
        "### (!) Comprobar \r\n",
        "Si utiliza un recurso de **Custom Vision**, ¿ha usado el recurso de **predicción** (y <u>no</u> el recurso de entrenamiento)?\r\n",
        "\r\n",
        "![Clave y punto de conexión del recurso de predicción en la configuración de Custom Vision](./images/cv_settings.jpg)\r\n",
        "\r\n",
        "13. Para establecer las variables de su ID de proyecto, clave y punto de conexión, haga clic en el botón **Run Cell** (&#9655;) (a la izquierda de la celda siguiente) y ejecute su código."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = 'YOUR_PROJECT_ID'\n",
        "cv_key = 'YOUR_KEY'\n",
        "cv_endpoint = 'YOUR_ENDPOINT'\n",
        "\n",
        "model_name = 'groceries' # esto debe coincidir con el nombre del modelo establecido al publicar la iteración del modelo (distingue mayúsculas de minúsculas).\n",
        "print('Ready to predict using model {} in project {}'.format(model_name, project_id))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599691949340
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, puede usar su clave y punto de conexión con un cliente de Custom Vision para conectarse a su modelo de clasificación de Custom Vision.\r\n",
        "\r\n",
        "Ejecute la siguiente celda de código para clasificar una selección de imágenes de prueba con su modelo publicado.\r\n",
        "\r\n",
        "> **Nota**: No se preocupe demasiado por los detalles del código. Utiliza el SDK de Computer Vision para Python para obtener una predicción de clase de cada imagen en la carpeta /data/image-classification/test-fruit"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
        "from msrest.authentication import ApiKeyCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# Obtener las imágenes de prueba de la carpeta data/vision/test\r\n",
        "test_folder = os.path.join('data', 'image-classification', 'test-fruit')\n",
        "test_images = os.listdir(test_folder)\n",
        "\n",
        "# Crear una instancia del servicio de predicción\r\n",
        "credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": cv_key})\n",
        "custom_vision_client = CustomVisionPredictionClient(endpoint=cv_endpoint, credentials=credentials)\n",
        "\n",
        "# Crear una figura para mostrar los resultados\r\n",
        "fig = plt.figure(figsize=(16, 8))\n",
        "\n",
        "# Obtener las imágenes y mostrar las clases de predicción de cada una\r\n",
        "print('Classifying images in {} ...'.format(test_folder))\n",
        "for i in range(len(test_images)):\n",
        "    # Abra la imagen y use el modelo de Custom Vision para clasificarla\n",
        "    image_contents = open(os.path.join(test_folder, test_images[i]), \"rb\")\n",
        "    classification = custom_vision_client.classify_image(project_id, model_name, image_contents.read())\n",
        "    # Entre los resultados se incluye una predicción para cada etiqueta, en orden descendente de probabilidad: obtenga la primera\n",
        "    prediction = classification.predictions[0].tag_name\n",
        "    # Muestre la imagen con su clase prevista\n",
        "    img = Image.open(os.path.join(test_folder, test_images[i]))\n",
        "    a=fig.add_subplot(len(test_images)/3, 3,i+1)\n",
        "    a.axis('off')\n",
        "    imgplot = plt.imshow(img)\n",
        "    a.set_title(prediction)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599692327514
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si todo va bien, su modelo de clasificación de imágenes identificará correctamente los artículos de las imágenes.\r\n",
        "\r\n",
        "## Más información\r\n",
        "\r\n",
        "El servicio Custom Vision ofrece más capacidades, además de las descritas en este ejercicio. Por ejemplo, también se puede usar el servicio Custom Vision para crear modelos de *detección de objetos* que no solo clasifican los objetos de las imágenes, también identifican *cuadros de límite* que muestran la ubicación de cada objeto en la imagen.\r\n",
        "\r\n",
        "Para más información sobre el servicio Custom Vision, de Cognitive Services, consulte la [documentación de Custom Vision](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/home)."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}