{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Voz\r\n",
        "\r\n",
        "Cada vez será más habitual comunicarnos con sistemas de inteligencia artificial (IA) mediante nuestra voz y, a menudo, esperaremos una respuesta hablada.\r\n",
        "\r\n",
        "![Un robot hablando](./images/speech.jpg)\r\n",
        "\r\n",
        "*Reconocimiento de voz* (un sistema de IA que interpreta el lenguaje hablado) y *Síntesis de voz* (un sistema de IA que genera una respuesta hablada) son los componentes principales de una solución de IA habilitada por voz.\r\n",
        "\r\n",
        "## Crear un recurso de Cognitive Services\r\n",
        "\r\n",
        "Para crear un software que pueda interpretar el lenguaje hablado y responder de la misma manera, puede usar **Voz** de Cognitive Services, que permite convertir lenguaje hablado en texto y viceversa.\r\n",
        "\r\n",
        "Si no tiene uno, siga estos pasos para crear un recurso de **Cognitive Services** en su suscripción de Azure:\r\n",
        "\r\n",
        "> **Nota**: Si ya tiene un recurso de Cognitive Services, abra su página de **Inicio rápido** en Azure Portal y copie la clave y el punto de conexión en la siguiente celda. En caso contrario, siga estos pasos para crear uno.\r\n",
        "\r\n",
        "1. En la pestaña de otro explorador, abra Azure Portal (https://portal.azure.com) e inicie sesión con su cuenta de Microsoft.\r\n",
        "2. Haga clic en el botón **&#65291;Crear un recurso**, busque *Cognitive Services* y cree un recurso de **Cognitive Services** con esta configuración:\r\n",
        "    - **Suscripción**: *su suscripción de Azure*.\r\n",
        "    - **Grupo de recursos**: *seleccione o cree un grupo de recursos con un nombre único.*\r\n",
        "    - **Región**: *seleccione cualquier región disponible*:\r\n",
        "    - **Nombre**: *escriba un nombre único*.\r\n",
        "    - **Plan de tarifa**: S0\r\n",
        "    - **Confirmo que he leído y comprendido las notificaciones**: seleccionado.\r\n",
        "3. Espere a que la implementación finalice. Vaya al recurso de Cognitive Services y, en la página **Información general**, haga clic en el vínculo para administrar las claves del servicio. Necesitará la clave y la ubicación para conectarse a su recurso de Cognitive Services desde aplicaciones de cliente.\r\n",
        "\r\n",
        "### Obtener la clave y la ubicación de un recurso de Cognitive Services\r\n",
        "\r\n",
        "Para usar su recurso de Cognitive Services, las aplicaciones de cliente necesitan su clave de autenticación y su ubicación:\r\n",
        "\r\n",
        "1. En Azure Portal, en la página **Claves y punto de conexión** de su recurso de Cognitive Services, copie la **Key1** de su recurso y péguela en el siguiente código, en sustitución de **YOUR_COG_KEY**.\r\n",
        "2. Copie la **Ubicación** de su recurso y péguela en el siguiente código, en sustitución de **YOUR_COG_LOCATION**.\r\n",
        ">**Nota**: Quédese en la página **Claves y punto de conexión** y copie la **Ubicación** desde esta página, (ejemplo: _westus_). No _agregue_ espacios entre las palabras del campo Ubicación. \r\n",
        "3. Ejecute el código siguiente. Para ello, haga clic en **Run cell** (&#9655;) a la izquierda de la celda."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_location = 'YOUR_COG_LOCATION'\n",
        "\n",
        "print('Ready to use cognitive services in {} using key {}'.format(cog_location, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599695240794
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reconocimiento de voz\r\n",
        "\r\n",
        "Digamos que quiere crear un sistema de automatización del hogar que acepte instrucciones habladas, como “turn the light on” para encender la luz y “turn the light off” para apagarla. Su aplicación debe ser capaz de reconocer el audio de su voz (su instrucción hablada), interpretarlo y convertirlo en texto para, después, procesarlo y analizarlo.\r\n",
        "\r\n",
        "Ya está listo para transcribir audio. La entrada de audio puede recibirse a través de un **micrófono** o mediante un **archivo de audio**. \r\n",
        "\r\n",
        "### Reconocimiento de voz procedente de un micrófono\r\n",
        "\r\n",
        "Primero, probaremos con un micrófono. Ejecute la siguiente celda y, **justo después**, diga **“turn the light on”** en voz alta. Las capacidades de conversión de voz en texto del servicio Voz transcribirán el audio. El resultado debería ser su instrucción hablada transcrita.\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import IPython\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, AudioConfig\n",
        "\n",
        "# Configurar el reconocedor de voz\r\n",
        "speech_config = SpeechConfig(cog_key, cog_location)\n",
        "\n",
        "# Pedir a los estudiantes que digan “turn the light on” \r\n",
        "speech_recognizer = SpeechRecognizer(speech_config)\n",
        "\n",
        "# Utilizar una llamada sincrónica única para transcribir la voz\r\n",
        "speech = speech_recognizer.recognize_once()\n",
        "\n",
        "print(speech.text)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599695250434
        }
      }
    },
    {
      "source": [
        "### (!) Comprobar\r\n",
        "\r\n",
        "¿Fue capaz de ejecutar la celta y transcribir su voz? Si la celda anterior no devuelve un resultado escrito (ejemplo: _Turn the light on._), vuelva a ejecutar la celda y diga “turn the light on” **inmediatamente** después.\r\n",
        "\r\n",
        "### Reconocimiento de voz con un archivo de audio\r\n",
        "\r\n",
        "Si la celda anterior no devuelve un resultado escrito, es posible que su micrófono no esté configurado. En cualquier caso, puede ejecutar la celda siguiente para ver cómo funciona el servicio Reconocimiento de voz con un **archivo de audio** en lugar de usar el **micrófono**. \r\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from playsound import playsound\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, AudioConfig\n",
        "\n",
        "# Obtener un comando hablado desde un archivo de audio\r\n",
        "file_name = 'light-on.wav'\n",
        "audio_file = os.path.join('data', 'speech', file_name)\n",
        "\n",
        "# Configurar el reconocedor de voz\r\n",
        "speech_config = SpeechConfig(cog_key, cog_location)\n",
        "audio_config = AudioConfig(filename=audio_file) # Utilice el archivo en lugar del valor predeterminado (micrófono)\n",
        "speech_recognizer = SpeechRecognizer(speech_config, audio_config)\n",
        "\n",
        "# Utilizar una llamada sincrónica única para transcribir la voz\r\n",
        "speech = speech_recognizer.recognize_once()\n",
        "\n",
        "# Reproducir audio y mostrar el texto transcrito\r\n",
        "playsound(audio_file)\n",
        "print(speech.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Síntesis de voz\r\n",
        "\r\n",
        "Ya hemos visto cómo usar el servicio Voz para transcribir el lenguaje hablado, pero ¿qué pasa si queremos convertir el texto en voz? ¿Cómo podemos hacerlo?\r\n",
        "\r\n",
        "Supongamos que su sistema de automatización del hogar ha interpretado un comando para encender la luz (“turn the light on”). Lo esperado sería que el sistema respondiera al comando y que, además, realizase la acción solicitada."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechSynthesizer, AudioConfig\n",
        "%matplotlib inline\n",
        "\n",
        "# Conseguir que el texto escrito se convierta en voz\r\n",
        "response_text = 'Turning the light on.'\n",
        "\n",
        "# Configurar la síntesis de voz\r\n",
        "speech_config = SpeechConfig(cog_key, cog_location)\n",
        "speech_synthesizer = SpeechSynthesizer(speech_config)\n",
        "\n",
        "# Convertir texto en voz\r\n",
        "result = speech_synthesizer.speak_text(response_text)\n",
        "\n",
        "# Mostrar una imagen adecuada \r\n",
        "file_name = response_text + \"jpg\"\n",
        "img = Image.open(os.path.join(\"data\", \"speech\", file_name))\n",
        "plt.axis('off')\n",
        "plt. imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599695261170
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cambie la variable **response_text** a *Turning the light off.* (incluido el punto final) y vuelva a ejecutar la celda para escuchar el resultado.\r\n",
        "\r\n",
        "## Más información\r\n",
        "\r\n",
        "En este cuaderno, hemos visto un sencillo ejemplo sobre cómo usar el servicio Voz, de Cognitive Services. Puede obtener más información sobre [Conversión de voz en texto](https://docs.microsoft.com/azure/cognitive-services/speech-service/index-speech-to-text) y [Conversión de texto en voz](https://docs.microsoft.com/azure/cognitive-services/speech-service/index-text-to-speech) en la documentación del servicio Voz."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.8.5-final",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 32-bit",
      "metadata": {
        "interpreter": {
          "hash": "177429bd1865e7f7a0dbecbac90518c0d9641b1102b2e6c0df4b82dc948b5cb2"
        }
      }
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}